{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PyTorch GTZANplus.ipynb","provenance":[{"file_id":"1lVO_B4ycmvwoYu7VdfTQ9zBDkT9datby","timestamp":1625419033801},{"file_id":"1qqKCclOC2zX29e94WcVgizfiTAipgbqe","timestamp":1625393273402}],"collapsed_sections":[],"authorship_tag":"ABX9TyOmTURYgQ3f0n3yLO6gKYfE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mb4Ho_KohjKQ"},"source":["**##############################################**\n","\n","**############ NETWORK ARCHITECTURE #############**\n","\n","**##############################################**"]},{"cell_type":"code","metadata":{"id":"KkMt7qb6hZ7R"},"source":["import torch\n","import torch.nn as nn\n","from functools import reduce\n","from operator import __add__"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tx44FDoIhxij"},"source":["def samePaddingOption(kernel_size):\n","    \"\"\"\n","    Internal parameters used to reproduce Tensorflow \"Same\" option for padding.\n","    :param kernel_size: dimension of the convolutional kernel\n","    :return: padding needed for \"Same\" result as in Tensorflow\n","    \"\"\"\n","    conv_padding = reduce(__add__, [(k // 2 + (k - 2 * (k // 2)) - 1, k // 2) for k in kernel_size[::-1]])\n","    return conv_padding"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"To7nbrYvh91G"},"source":["class CRNN2D(nn.Module):\n","\n","    def __init__(self, X_shape, nb_classes, nb_filters, kernel_size, pool_size, GRU_hidden_size):\n","        \"\"\"\n","        Constructor, performing class instance initialization\n","        :param X_shape: shape of input data (N, H, W, C)\n","        :param nb_classes: number of possible final classes (artists)\n","        :param nb_filters: number of filters\n","        :param kernel_size: kernel size\n","        :param pool_size: pooling size\n","        :param GRU_hidden_size: hidden size for the GRU\n","        :param GRU_num_layers: number of GRUs\n","        \"\"\"\n","        super(CRNN2D, self).__init__()\n","\n","        # Filter sizes\n","        self.nb_filters = nb_filters\n","        # Convolution kernel size\n","        self.kernel_size = kernel_size\n","        # Size of pooling area\n","        self.pool_size = pool_size\n","        # GRU hidden size\n","        self.GRU_hidden_size = GRU_hidden_size\n","        # Compute padding\n","        self.padding = samePaddingOption(kernel_size=kernel_size)\n","\n","        # Normalization over frequency dimension\n","        self.norm0 = nn.BatchNorm2d(num_features=X_shape[1], eps=0.001, momentum=0.01)\n","\n","        ### First convolutional layer ###\n","        self.pad1 = nn.ZeroPad2d(padding=self.padding)\n","        self.conv1 = nn.Conv2d(in_channels=X_shape[3], out_channels=nb_filters[0], kernel_size=kernel_size)\n","        # Activation function\n","        self.elu1 = nn.ELU()\n","        # Normalization over channel dimension\n","        self.norm1 = nn.BatchNorm2d(num_features=nb_filters[0], eps=0.001, momentum=0.01)\n","        # MaxPool\n","        self.maxp1 = nn.MaxPool2d(kernel_size=pool_size[0])\n","        # Dropout\n","        self.drop1 = nn.Dropout(p=0.1)\n","\n","        ### Second convolutional layer ###\n","        self.pad2 = nn.ZeroPad2d(padding=self.padding)\n","        self.conv2 = nn.Conv2d(in_channels=nb_filters[0], out_channels=nb_filters[1], kernel_size=kernel_size)\n","        # Activation function\n","        self.elu2 = nn.ELU()\n","        # Normalization over channel dimension\n","        self.norm2 = nn.BatchNorm2d(num_features=nb_filters[1], eps=0.001, momentum=0.01)\n","        # MaxPool\n","        self.maxp2 = nn.MaxPool2d(kernel_size=pool_size[1])\n","        # Dropout\n","        self.drop2 = nn.Dropout(p=0.1)\n","\n","        ### Third convolutional layer ###\n","        self.pad3 = nn.ZeroPad2d(padding=self.padding)\n","        self.conv3 = nn.Conv2d(in_channels=nb_filters[1], out_channels=nb_filters[2], kernel_size=kernel_size)\n","        # Activation function\n","        self.elu3 = nn.ELU()\n","        # Normalization over channel dimension\n","        self.norm3 = nn.BatchNorm2d(num_features=nb_filters[2], eps=0.001, momentum=0.01)\n","        # MaxPool\n","        self.maxp3 = nn.MaxPool2d(kernel_size=pool_size[2])\n","        # Dropout\n","        self.drop3 = nn.Dropout(p=0.1)\n","\n","        ### Fourth convolutional layer ###\n","        self.pad4 = nn.ZeroPad2d(padding=self.padding)\n","        self.conv4 = nn.Conv2d(in_channels=nb_filters[2], out_channels=nb_filters[3], kernel_size=kernel_size)\n","        # Activation function\n","        self.elu4 = nn.ELU()\n","        # Normalization over channel dimension\n","        self.norm4 = nn.BatchNorm2d(num_features=nb_filters[3], eps=0.001, momentum=0.01)\n","        # MaxPool\n","        self.maxp4 = nn.MaxPool2d(kernel_size=pool_size[3])\n","        # Dropout\n","        self.drop4 = nn.Dropout(p=0.1)\n","\n","        ### First and Second recurrent layers (stacked) ###\n","        self.gru1 = nn.GRU(input_size=nb_filters[3], hidden_size=self.GRU_hidden_size, \\\n","                           batch_first=True)\n","        self.gru2 = nn.GRU(input_size=self.GRU_hidden_size, hidden_size=self.GRU_hidden_size, \\\n","                           batch_first=True)\n","        # Dropout\n","        self.drop5 = nn.Dropout(p=0.3)\n","\n","        ### Final fully-connected layer ###\n","        self.fc = nn.Linear(in_features=self.GRU_hidden_size, out_features=nb_classes)\n","        # SoftMax\n","        #self.smax = nn.Softmax(dim=1)\n","\n","    def forward(self, x, test=False):\n","        \"\"\"\n","        Function describing data path through the network\n","        :param x: input data\n","        :param test: boolean value to determine if the forward pass is happening \n","                     in testing or not. Since the former takes place in CPU \n","                     and the latter in GPU, it flags where to save h0 (in GRU)\n","        :return: output data\n","        \"\"\"\n","\n","        # starting as (N, H, W, C) -> norm along H -> (N, C, H, W)\n","        out = self.norm0(x)\n","        out = out.permute((0, 3, 1, 2))\n","\n","        # First convolutional layer\n","        out = self.pad1(out)\n","        out = self.conv1(out)\n","        out = self.elu1(out)\n","        out = self.norm1(out)\n","        out = self.maxp1(out)\n","        out = self.drop1(out)\n","\n","        # Second convolutional layer\n","        out = self.pad2(out)\n","        out = self.conv2(out)\n","        out = self.elu2(out)\n","        out = self.norm2(out)\n","        out = self.maxp2(out)\n","        out = self.drop2(out)\n","\n","        # Third convolutional layer\n","        out = self.pad3(out)\n","        out = self.conv3(out)\n","        out = self.elu3(out)\n","        out = self.norm3(out)\n","        out = self.maxp3(out)\n","        out = self.drop3(out)\n","\n","        # Fourth convolutional layer\n","        out = self.pad4(out)\n","        out = self.conv4(out)\n","        out = self.elu4(out)\n","        out = self.norm4(out)\n","        out = self.maxp4(out)\n","        out = self.drop4(out)\n","\n","        # Before giving the data to the GRU, a reshaping is needed\n","        # (N, C, H, W) -> (N, W, C)\n","        out = out.squeeze(2).permute((0, 2, 1))\n","\n","        # First and Second recurrent layers\n","        h0 = torch.zeros(1, out.shape[0], self.GRU_hidden_size)\n","        if torch.cuda.is_available() and (not test):\n","          h0 = h0.cuda()\n","        out, _ = self.gru1(out, h0)\n","        _, out = self.gru2(out, h0)\n","        # Now out is in the form (1, batch, self.GRU_hidden_size)\n","        out = out[0]\n","\n","        out = self.drop5(out)\n","        # Final fully-connected layer\n","        out = self.fc(out)\n","        #out = self.smax(out)\n","\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AGB7zSZ0ihjE"},"source":["**#############################################**\n","\n","**############### DATASET CLASS #################**\n","\n","**#############################################**"]},{"cell_type":"code","metadata":{"id":"p0tp0hOOiZrP"},"source":["from torch.utils.data import Dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oVeDce_EjEPl"},"source":["class DatasetArtist20(Dataset):\n","\n","    def __init__(self, data, labels, transform=None):\n","        \"\"\"\n","        Initial processing\n","        :param data: training data\n","        :param labels: labels corresponding to data\n","        :param transform: required pre-processing\n","        \"\"\"\n","        self.data = data\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        \"\"\"\n","        Return the total number of samples in the dataset.\n","        :return: total number of samples in the dataset\n","        \"\"\"\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Given and index return a data sample.\n","        :param index: index\n","        :return: data sample corresponding to index\n","        \"\"\"\n","        image = self.data[index]\n","        label = self.labels[index]\n","\n","        if self.transform is not None:\n","            image = self.transform(image)\n","\n","        return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d583Q2Z1j0a-"},"source":["**############################################**\n","\n","**################## UTILITIES ##################**\n","\n","**############################################**"]},{"cell_type":"code","metadata":{"id":"F-zqelKvjHel"},"source":["import os\n","import dill\n","import itertools\n","import torchvision\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import gc\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.utils import shuffle\n","from sklearn import preprocessing\n","from torch.utils.data import DataLoader\n","from scipy import stats\n","from os.path import isfile"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WIF_OOe4j75E"},"source":["def load_dataset(song_folder_name='song_data', artist_folder='artists', nb_classes=20, random_state=42):\n","    \"\"\"\n","    This function loads the dataset based on a location; it returns a list of spectrograms\n","    and their corresponding artists/song names\n","    :param song_folder_name: folder containing the songs saved as numpy arrays\n","    :param artist_folder: folder with the correct structure (artist_folder/artists/albums/*.mp3)\n","    :param nb_classes: number of artists\n","    :param random_state: random state to fix the choice\n","    :return: list of spectrograms - 2D np.arrays of shape (128, x(t)) - and lists with corresponding artists/song names\n","    \"\"\"\n","\n","    # Get all songs saved as numpy arrays in the given folder\n","    song_list = os.listdir(song_folder_name)\n","    song_list.sort()\n","\n","    # Load the list of artists\n","    artist_list = os.listdir(artist_folder)\n","    artist_list.sort()\n","\n","    # select the appropriate number of classes\n","    prng = np.random.RandomState(random_state)\n","    artists = prng.choice(artist_list, size=nb_classes, replace=False)\n","\n","    # Create empty lists\n","    artist = []\n","    spectrogram = []\n","    song_name = []\n","\n","    # Load each song into memory if the artist is included and return\n","    for song in song_list:\n","        with open(os.path.join(song_folder_name, song), 'rb') as fp:\n","            loaded_song = dill.load(fp)\n","        if loaded_song[0] in artists:\n","            artist.append(loaded_song[0])\n","            spectrogram.append(loaded_song[1])\n","            song_name.append(loaded_song[2])\n","\n","    return artist, spectrogram, song_name"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a2cUrzm9jot5"},"source":["def load_dataset_album_split(song_folder_name='song_data', artist_folder='artists', nb_classes=20, random_state=42):\n","    \"\"\"\n","    This function loads a dataset and splits it on an album level.\n","    :param song_folder_name: folder containing the songs saved as numpy arrays\n","    :param artist_folder: folder with the correct structure (artist_folder/artists/albums/*.mp3)\n","    :param nb_classes: number of artists\n","    :param random_state: random state to fix the choice\n","    :return: train, validation and test sets from the dataset splitted on an album level\n","    \"\"\"\n","    song_list = os.listdir(song_folder_name)\n","    song_list.sort()\n","\n","    # Load the list of artists\n","    artist_list = os.listdir(artist_folder)\n","    artist_list.sort()\n","\n","    train_albums = []\n","    test_albums = []\n","    val_albums = []\n","    np.random.seed(random_state)\n","    for artist in artist_list:\n","        albums = os.listdir(os.path.join(artist_folder, artist))\n","        # Shuffling (seed previously defined)\n","        np.random.shuffle(albums)\n","        # One album in the test set\n","        test_albums.append(artist + '_%%-%%_' + albums.pop(0))\n","        # One album in the validation set\n","        val_albums.append(artist + '_%%-%%_' + albums.pop(0))\n","        # Remaining albums in the train set\n","        train_albums.extend([artist + '_%%-%%_' + album for album in albums])\n","\n","    # select the appropriate number of classes\n","    prng = np.random.RandomState(random_state)\n","    artists = prng.choice(artist_list, size=nb_classes, replace=False)\n","\n","    # Create empty lists\n","    Y_train, Y_test, Y_val = [], [], []\n","    X_train, X_test, X_val = [], [], []\n","    S_train, S_test, S_val = [], [], []\n","\n","    # Load each song into memory if the artist is included and return\n","    for song in song_list:\n","        with open(os.path.join(song_folder_name, song), 'rb') as fp:\n","            loaded_song = dill.load(fp)\n","        artist, album, song_name = song.split('_%%-%%_')\n","        artist_album = artist + '_%%-%%_' + album\n","\n","        if loaded_song[0] in artists:\n","            if artist_album in train_albums:\n","                Y_train.append(loaded_song[0])\n","                X_train.append(loaded_song[1])\n","                S_train.append(loaded_song[2])\n","            elif artist_album in test_albums:\n","                Y_test.append(loaded_song[0])\n","                X_test.append(loaded_song[1])\n","                S_test.append(loaded_song[2])\n","            elif artist_album in val_albums:\n","                Y_val.append(loaded_song[0])\n","                X_val.append(loaded_song[1])\n","                S_val.append(loaded_song[2])\n","\n","    return Y_train, X_train, S_train, \\\n","           Y_test, X_test, S_test, \\\n","           Y_val, X_val, S_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wchBEdiBkP0O"},"source":["def load_dataset_song_split(song_folder_name='song_data', artist_folder='artists', nb_classes=20, \\\n","                            test_split_size=0.1, validation_split_size=0.1, random_state=42):\n","    \"\"\"\n","    This function loads a dataset and splits it on a song level.\n","    :param song_folder_name: folder containing the songs saved as numpy arrays\n","    :param artist_folder: folder with the correct structure (artist_folder/artists/albums/*.mp3)\n","    :param nb_classes: number of artists\n","    :param test_split_size: ratio |test_size| / (|train_size| + |validation_size|)\n","    :param validation_split_size: ratio |validation_size| / |train_size|\n","    :param random_state: random state to fix the choice\n","    :return: train, validation and test sets from the dataset splitted on a song level\n","    \"\"\"\n","    Y, X, S = load_dataset(song_folder_name=song_folder_name, artist_folder=artist_folder, \\\n","                           nb_classes=nb_classes, random_state=random_state)\n","\n","    # train and test split\n","    X_train, X_test, Y_train, Y_test, S_train, S_test = train_test_split(X, Y, S, test_size=test_split_size, \\\n","                                                                         stratify=Y, random_state=random_state)\n","\n","    # Create a validation to be used to track progress\n","    X_train, X_val, Y_train, Y_val, S_train, S_val = train_test_split(X_train, Y_train, S_train, \\\n","                                                                      test_size=validation_split_size, shuffle=True, \\\n","                                                                      stratify=Y_train, random_state=random_state)\n","\n","    return Y_train, X_train, S_train, \\\n","           Y_test, X_test, S_test, \\\n","           Y_val, X_val, S_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N8V51OPAkWYJ"},"source":["def slice_songs(X, Y, S, length=911):\n","    \"\"\"\n","    Slices the spectrogram into sub-spectrograms according to length.\n","    :param X: spectrograms\n","    :param Y: artists\n","    :param S: song names\n","    :param length: length of slices\n","    :return: 3D np.array of sliced spectrograms (num_slices, 128, length), with corresponding artists and names arrays\n","    \"\"\"\n","\n","    # Create empty lists for train and test sets\n","    artist = []\n","    spectrogram = []\n","    song_name = []\n","\n","    # Slice up songs using the length specified\n","    for i, song in enumerate(X):\n","        slices = int(song.shape[1] / length)\n","        for j in range(slices - 1):\n","            spectrogram.append(song[:, length * j:length * (j + 1)])\n","            artist.append(Y[i])\n","            song_name.append(S[i])\n","\n","    return np.array(spectrogram), np.array(artist), np.array(song_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOVL7iz_SD59"},"source":["def augment_train_set(X_train, Y_train, S_train, artist_folder='artists', augment_folder='augmented', sr=22050, length=94):\n","    \"\"\"\n","    Data augmentation for train set.\n","    :param X_train: original spectrogram train set\n","    :param Y_train: original genre train set\n","    :param S_train: original song train set\n","    \"\"\"\n","\n","    X_augm = []\n","    Y_augm = []\n","    S_augm = []\n","\n","    genres = os.listdir(augment_folder)\n","    # Check only for songs in train set\n","    for genre in genres:\n","        songs_UP = os.listdir(augment_folder + '/' + genre + '/' + genre + '_UP')\n","\n","        for song in songs_UP:\n","            if song in S_train:\n","                y_UP, sr = librosa.load(augment_folder + '/' + genre + '/' + genre + '_UP/' + song, sr=sr)\n","                # It has the same title\n","                y_DOWN, sr = librosa.load(augment_folder + '/' + genre + '/' + genre + '_DOWN/' + song, sr=sr)\n","                S_UP = librosa.feature.melspectrogram(y_UP, sr=sr, n_mels=128, \\\n","                                                      n_fft=2048, \\\n","                                                      hop_length=512)\n","                log_S_UP = librosa.amplitude_to_db(S_UP, ref=1.0)\n","                S_DOWN = librosa.feature.melspectrogram(y_DOWN, sr=sr, n_mels=128, \\\n","                                                        n_fft=2048, \\\n","                                                        hop_length=512)\n","                log_S_DOWN = librosa.amplitude_to_db(S_DOWN, ref=1.0)\n","                X_augm.append(log_S_UP)\n","                X_augm.append(log_S_DOWN)\n","                Y_augm.append(genre)\n","                Y_augm.append(genre)\n","                S_augm.append(song)\n","                S_augm.append(song)\n","\n","                # Do the same with overlapped window\n","                oneAndHalfSec = int(np.floor(y_UP.shape[0]/20))\n","                y_UP = y_UP[oneAndHalfSec:-oneAndHalfSec] # 1.5s shift\n","                y_DOWN = y_DOWN[oneAndHalfSec:-oneAndHalfSec] # 1.5s shift\n","                S_UP = librosa.feature.melspectrogram(y_UP, sr=sr, n_mels=128, \\\n","                                                      n_fft=2048, \\\n","                                                      hop_length=512)\n","                log_S_UP = librosa.amplitude_to_db(S_UP, ref=1.0)\n","                S_DOWN = librosa.feature.melspectrogram(y_DOWN, sr=sr, n_mels=128, \\\n","                                                        n_fft=2048, \\\n","                                                        hop_length=512)\n","                log_S_DOWN = librosa.amplitude_to_db(S_DOWN, ref=1.0)\n","                X_augm.append(log_S_UP)\n","                X_augm.append(log_S_DOWN)\n","                Y_augm.append(genre)\n","                Y_augm.append(genre)\n","                S_augm.append(song)\n","                S_augm.append(song)\n","\n","                # Overlap olso original song\n","                y, sr = librosa.load(artist_folder + '/' + genre + '/' + genre + '_/' + song, sr=sr)\n","                y = y[oneAndHalfSec:-oneAndHalfSec] # 1.5s shift\n","                S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128, \\\n","                                                   n_fft=2048, \\\n","                                                   hop_length=512)\n","                log_S = librosa.amplitude_to_db(S, ref=1.0)\n","                X_augm.append(log_S)\n","                Y_augm.append(genre)\n","                S_augm.append(song)\n","\n","    # Split augmented data\n","    X_augm, Y_augm, S_augm = slice_songs(X_augm, Y_augm, S_augm, length=length)\n","\n","    # Concat results\n","    X_train = np.vstack((X_train, X_augm))\n","    Y_train = np.hstack((Y_train, Y_augm))\n","    S_train = np.hstack((S_train, S_augm))\n","\n","    return X_train, Y_train, S_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GC9iU-PJkcgJ"},"source":["def encode_labels(Y, le=None, enc=None):\n","    \"\"\"\n","    Encodes target variables into numbers and then one hot encodings.\n","    :param Y: array of target variables (artists)\n","    :param le: label encoder\n","    :param enc: one hot encoder\n","    :return: one-hot-encoded array together with label and one hot encoder for future use\n","    \"\"\"\n","    # initialize encoders\n","    N = Y.shape[0]\n","\n","    # Encode the labels\n","    if le is None:\n","        le = preprocessing.LabelEncoder()\n","        Y_le = le.fit_transform(Y).reshape(N, 1)\n","    else:\n","        Y_le = le.transform(Y).reshape(N, 1)\n","\n","    # convert into one hot encoding\n","    if enc is None:\n","        enc = preprocessing.OneHotEncoder()\n","        Y_enc = enc.fit_transform(Y_le).toarray()\n","    else:\n","        Y_enc = enc.transform(Y_le).toarray()\n","\n","    # return encoders to re-use on other data\n","    return Y_enc, le, enc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aErXG1Kikkf3"},"source":["def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.get_cmap('Blues')):\n","    \"\"\"\n","    This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`.\n","    :param cm: confusion matrix\n","    :param classes: classes taken into account\n","    :param normalize: boolean value to apply normalization to the matrix\n","    :param title: title\n","    :param cmap: color map\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", \\\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cdah5PGPkoaS"},"source":["def predict_artist(model, X, Y, S, le, class_names, slices=None, verbose=False, ml_mode=False):\n","    \"\"\"\n","    This function takes slices of songs and predicts their output. For each song, it votes on the most frequent artist.\n","    :param model: model\n","    :param X: spectrograms\n","    :param Y: artists\n","    :param S: song names\n","    :param le: label encoder\n","    :param class_names: names of the classes taken into account\n","    :param slices: value used to check if/how many slices has been created\n","    :param verbose: boolean value used as verbosity choice\n","    :param ml_mode:\n","    :return:\n","    \"\"\"\n","    print(\"Test results when pooling slices by song and voting:\")\n","    # Obtain the list of songs\n","    songs = np.unique(S)\n","\n","    prediction_list = []\n","    actual_list = []\n","\n","    # Iterate through each song\n","    for song in songs:\n","\n","        # Grab all slices related to a particular song\n","        X_song = X[S == song]\n","        Y_song = Y[S == song]\n","\n","        # If not using full song, shuffle and take up to a number of slices\n","        if slices and slices <= X_song.shape[0]:\n","            X_song, Y_song = shuffle(X_song, Y_song)\n","            X_song = X_song[:slices]\n","            Y_song = Y_song[:slices]\n","\n","        # Get probabilities of each class\n","        model.eval()\n","        predictions = model(X_song, test=True)\n","\n","        if not ml_mode:\n","            # Get list of highest probability classes and their probability\n","            class_prediction = np.argmax(predictions.detach().numpy(), axis=1)\n","            class_probability = np.max(predictions.detach().numpy(), axis=1)\n","\n","            # keep only predictions confident about;\n","            prediction_summary_trim = class_prediction[class_probability > 0.5]\n","\n","            # deal with edge case where there is no confident class\n","            if len(prediction_summary_trim) == 0:\n","                prediction_summary_trim = class_prediction\n","        else:\n","            prediction_summary_trim = predictions\n","            \n","        # get most frequent class\n","        prediction = stats.mode(prediction_summary_trim)[0][0]\n","        actual = stats.mode(np.argmax(Y_song))[0][0]\n","\n","        # Keeping track of overall song classification accuracy\n","        prediction_list.append(prediction)\n","        actual_list.append(actual)\n","\n","        # Print out prediction\n","        if verbose:\n","            print(song)\n","            print(\"Predicted:\", le.inverse_transform(prediction), \"\\nActual:\", \\\n","                  le.inverse_transform(actual))\n","            print('\\n')\n","\n","    # Print overall song accuracy\n","    actual_array = np.array(actual_list)\n","    prediction_array = np.array(prediction_list)\n","    cm = confusion_matrix(actual_array, prediction_array)\n","    plot_confusion_matrix(cm, classes=class_names, normalize=True, \\\n","                          title='Confusion matrix for pooled results' + \\\n","                                ' with normalization')\n","    class_report = classification_report(actual_array, prediction_array, \\\n","                                         target_names=class_names)\n","    print(class_report)\n","\n","    class_report_dict = classification_report(actual_array, prediction_array, \\\n","                                              target_names=class_names, \\\n","                                              output_dict=True)\n","    return (class_report, class_report_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H2Ej_PJ5k12t"},"source":["**#############################################**\n","\n","**############## TRAINING FUNCTION ##############**\n","\n","**#############################################**"]},{"cell_type":"code","metadata":{"id":"gncDUL1D8kWn"},"source":["def train_model(nb_classes=20, slice_length=911, artist_folder='artists', song_folder='song_data', augment_folder='augmented', plots=True, \\\n","                train=True, load_checkpoint=False, save_metrics=True, save_metrics_folder='metrics', \\\n","                save_weights_folder='weights', batch_size=16, nb_epochs=200, lr=0.0001, patience=10, \\\n","                album_split=True, random_states=42):\n","    \"\"\"\n","    Main function for training the model and testing.\n","    :param nb_classes: number of artists\n","    :param slice_length: length of slices\n","    :param artist_folder: folder with the correct structure (artist_folder/artists/albums/*.mp3)\n","    :param song_folder: folder containing the songs saved as numpy arrays\n","    :param augment_folder: folder containing the songs for train set data augmentation\n","    :param plots: boolean value for plotting the training and validation loss per epoch of training\n","    :param train: boolean value for training or not the model\n","    :param load_checkpoint: boolean value to validate if loading previous \"weights checkpoint\"\n","    :param save_metrics: boolean value for saving data/images regarding metric evaluations\n","    :param save_metrics_folder: the folder where to save data regarding metric evaluations\n","    :param save_weights_folder: the folder where to save \"weights checkpoint\" configurations\n","    :param batch_size: batch size\n","    :param nb_epochs: number of epochs for the training\n","    :param lr: learning rate for optimizer\n","    :param patience: number of following epochs without validation loss improvement necessary to earlystop\n","    :param album_split: boolean value for album/song split\n","    :param random_states: random state to fix the choice\n","    :return: (dictionary of scores, dictionary of pooled scores)\n","    \"\"\"\n","    # Hyperparameters\n","    nb_filters = [64, 128, 128, 128]  # filter sizes\n","    kernel_size = (3, 3)  # convolution kernel size\n","    pool_size = [(2, 2), (4, 2), (4, 2), (4, 2), (4, 2)]  # size of pooling area\n","    GRU_hidden_size = 32  # GRU size\n","\n","    print(\"Loading dataset...\")\n","    # Load the dataset\n","    if not album_split:\n","        # Song split\n","        mode = 'song'\n","        Y_train, X_train, S_train, Y_test, X_test, S_test, \\\n","        Y_val, X_val, S_val = \\\n","            load_dataset_song_split(song_folder_name=song_folder, artist_folder=artist_folder, \\\n","                                    nb_classes=nb_classes, random_state=random_states)\n","    else:\n","        # Album split\n","        mode = 'album'\n","        Y_train, X_train, S_train, Y_test, X_test, S_test, \\\n","        Y_val, X_val, S_val = \\\n","            load_dataset_album_split(song_folder_name=song_folder, artist_folder=artist_folder, \\\n","                                     nb_classes=nb_classes, random_state=random_states)\n","            \n","    # Folders\n","    weights = os.path.join(save_weights_folder, str(nb_classes) + \\\n","                           '_' + str(slice_length) + '_' + str(random_states)) + \\\n","                           '_' + mode\n","    os.makedirs(save_weights_folder, exist_ok=True)\n","    os.makedirs(save_metrics_folder, exist_ok=True)\n","\n","    print(\"Loaded and split dataset. Slicing songs...\")\n","    X_train, Y_train, S_train = slice_songs(X_train, Y_train, S_train, length=slice_length)\n","    X_val, Y_val, S_val = slice_songs(X_val, Y_val, S_val, length=slice_length)\n","    X_test, Y_test, S_test = slice_songs(X_test, Y_test, S_test, length=slice_length)\n","\n","    # Augment train set\n","    print(\"Augmenting train set...\")\n","    X_train, Y_train, S_train = augment_train_set(X_train, Y_train, S_train, artist_folder=artist_folder, \\\n","                                                  augment_folder=augment_folder, sr=22050, length=slice_length)\n","\n","    print(\"Training set label counts:\", np.unique(Y_train, return_counts=True))\n","\n","    # Encode the target vectors into one-hot encoded vectors\n","    Y_train, le, enc = encode_labels(Y_train)\n","    Y_test, le, enc = encode_labels(Y_test, le, enc)\n","    Y_val, le, enc = encode_labels(Y_val, le, enc)\n","\n","    # Initialize the model\n","    # Recall that X_* is memorized as (num_slices, 128, slice_length). Now data is therefore memorized as (N, H, W).\n","    # Let's reshape it to (N, H, W, C) since first batch normalization is along H\n","    X_train = X_train.reshape(X_train.shape + (1,))\n","    X_val = X_val.reshape(X_val.shape + (1,))\n","    X_test = X_test.reshape(X_test.shape + (1,))\n","\n","    X_train = torch.from_numpy(X_train)\n","    Y_train = torch.from_numpy(Y_train)\n","    X_val = torch.from_numpy(X_val)\n","    Y_val = torch.from_numpy(Y_val)\n","    X_test = torch.from_numpy(X_test)\n","    Y_test = torch.from_numpy(Y_test)\n","\n","    # Define the model\n","    model = CRNN2D(X_shape=X_train.shape, nb_classes=Y_train.shape[1], nb_filters=nb_filters, \\\n","                   kernel_size=kernel_size, pool_size=pool_size, GRU_hidden_size=GRU_hidden_size)\n","\n","    if load_checkpoint:\n","        print(\"Looking for previous weights...\")\n","        if isfile(weights):\n","            print('Checkpoint file detected. Loading weights.')\n","            model.load_state_dict(torch.load(weights))\n","        else:\n","            print('No checkpoint file detected.  Starting from scratch.')\n","    else:\n","        print('Starting from scratch (no checkpoint)')\n","\n","    if train:\n","\n","        # Transfer model to GPU, if available\n","        if torch.cuda.is_available():\n","            model = model.cuda()\n","\n","        # Create training dataloader\n","        train_loader = DataLoader(DatasetArtist20(X_train, Y_train), batch_size=batch_size, shuffle=True)\n","        # Create validation dataloader\n","        valid_loader = DataLoader(DatasetArtist20(X_val, Y_val), batch_size=batch_size, shuffle=True)\n","\n","        # Define loss function\n","        # It is different from the Keras categorical_crossentropy loss, here the (log)softmax is \n","        # implemented in PyTorch CrossEntropyLoss and it is therefore disabled in the Architecture\n","        criterion = torch.nn.CrossEntropyLoss()\n","\n","        # Define optimizer\n","        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","        # Flag to check for loss decrease and save \"checkpoint\" for best configuration\n","        min_valid_loss = np.inf\n","\n","        # Train/Validation loop\n","        if plots:\n","            training = []\n","            validation = []\n","\n","        # Counter of following \"improvement-less\" epochs\n","        no_improv = 0\n","        epoch = 0\n","\n","        while (epoch < nb_epochs) and (no_improv < patience):\n","\n","            train_loss = 0.0\n","            tot_train_samples = 0.0\n","            # Prepare for train\n","            model.train()\n","            for i, data in enumerate(train_loader):\n","                # Step 1: Retrieving a batch of input from the dataloader\n","                inputs, labels = data\n","                # Transfer data to GPU, if available\n","                if torch.cuda.is_available():\n","                    inputs = inputs.cuda()\n","                    labels = labels.cuda()\n","                tot_train_samples += inputs.size(0)\n","                # Step 2: Zeroing the parameter gradients\n","                optimizer.zero_grad()\n","                # Step 3: forward (get network prediction)\n","                outputs = model(inputs, test=False)\n","                # Step 4: compute loss\n","                loss = criterion(outputs, torch.max(labels, 1)[1])\n","                # Step 5: Compute gradients for each of the model learnable parameters\n","                loss.backward()\n","                # Step 6: Update model parameters according to the gradients\n","                optimizer.step()\n","                # logging, accumulating loss value for current epoch...\n","                train_loss += (loss.item() * inputs.size(0))\n","            # End train epoch here\n","\n","            valid_loss = 0.0\n","            tot_valid_samples = 0.0\n","            # Prepare for validation\n","            model.eval()\n","            for i, data in enumerate(valid_loader):\n","                # Retrieving a batch of input from the dataloader\n","                inputs, labels = data\n","                # Transfer data to GPU, if available\n","                if torch.cuda.is_available():\n","                    inputs = inputs.cuda()\n","                    labels = labels.cuda()\n","                tot_valid_samples += inputs.size(0)\n","                # Forward pass\n","                outputs = model(inputs, test=False)\n","                # Find the loss\n","                loss = criterion(outputs, torch.max(labels, 1)[1])\n","                # logging, accumulating loss value for current epoch...\n","                valid_loss += (loss.item() * inputs.size(0))\n","            #End validation epoch here\n","\n","            print(f'Epoch {epoch + 1} \\t\\t Training Loss: {train_loss / tot_train_samples:.6f} '\n","                  f'\\t\\t Validation Loss: {valid_loss / tot_valid_samples:.6f}')\n","\n","            if plots:\n","                training.append(train_loss / tot_train_samples)\n","                validation.append(valid_loss / tot_valid_samples)\n","            \n","            # Increase the \"improvement-less\" counter (eventually reset to 0 in the following snippet)\n","            no_improv += 1\n","\n","            # \"Checkpoint\"-like search for best validation configuration\n","            if min_valid_loss > valid_loss / tot_valid_samples:\n","                print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss / tot_valid_samples:.6f}) \\t Saving The Model')\n","                min_valid_loss = valid_loss / tot_valid_samples\n","                # Saving state dictionary\n","                torch.save(model.state_dict(), weights)\n","                # Restore the \"improvement-less\" counter\n","                no_improv = 0\n","\n","            # Upgrade epoch\n","            epoch += 1\n","        # End Training here\n","\n","        if no_improv == patience:\n","            print(f'Reached limit of {patience} epochs without validation loss improvement: EarlyStopping.')\n","\n","        if plots:\n","            # Plot the training and validation losses for each epoch\n","            plt.figure(figsize=(14, 14))\n","            plt.plot(np.arange(epoch)+1, training)\n","            plt.plot(np.arange(epoch)+1, validation)\n","            plt.title('Training and validation losses')\n","            plt.ylabel('loss')\n","            plt.xlabel('epoch')\n","            plt.legend(['train', 'validation'], loc='lower left')\n","            path = os.path.join(save_metrics_folder, str(nb_classes) + '_' + str(slice_length) + '_' \\\n","                                + str(random_states) + '_' + mode)\n","            plt.savefig(path + '_losses_plot.png', bbox_inches=\"tight\")\n","            plt.close()\n","\n","        # Load state dictionary that gave best performance on validation set\n","        model.load_state_dict(torch.load(weights))\n","\n","    # Evaluate test data on batches to avoid memory problems (shuffle=False)\n","    test_loader = DataLoader(DatasetArtist20(X_test, Y_test), batch_size=batch_size, shuffle=False)\n","    # Model back on CPU for memory issues (if previously moved to GPU)\n","    if torch.cuda.is_available() and train:\n","        model = model.cpu()\n","    # Prepare for evaluation\n","    model.eval()\n","    print(\"Testing model...\")\n","    # Free RAM\n","    X_train_shape = X_train.shape\n","    del X_train, Y_train, S_train, X_val, Y_val, S_val\n","    if train:\n","        del train_loader, valid_loader, inputs, labels, data\n","    gc.collect()\n","    # Initialize tensor for batch hstacking (everything in CPU)\n","    Y_predict = np.array([], dtype=np.int16)\n","    for i, data in enumerate(test_loader):\n","        # Retrieving a batch of input from the dataloader\n","        inputs, labels = data\n","        # Forward (get network prediction)\n","        outputs = model(inputs, test=True)\n","        outputs_pred = np.argmax(outputs.detach().numpy(), axis=1)\n","        Y_predict = np.hstack((Y_predict, outputs_pred))\n","\n","    # Original labels for classes\n","    class_names = np.arange(nb_classes)\n","    class_names_original = le.inverse_transform(class_names)\n","\n","    # Compute the confusion matrix\n","    # Extract the label corresponding to highest probabilities\n","    #Y_predict = np.argmax(Y_score, axis=1)\n","    Y_true = np.argmax(Y_test, axis=1)\n","    cm = confusion_matrix(Y_true, Y_predict)\n","\n","    # Plot the confusion matrix\n","    plt.figure(figsize=(14, 14))\n","    plot_confusion_matrix(cm, classes=class_names_original, normalize=True, title='Confusion matrix with normalization')\n","    if save_metrics:\n","        filename = os.path.join(save_metrics_folder, str(nb_classes) + '_' + str(slice_length) + '_'\n","                                + str(random_states) + '_' + mode)\n","        plt.savefig(filename + '_confusion_matrix.png', bbox_inches=\"tight\")\n","    plt.close()\n","    plt.figure(figsize=(14, 14))\n","\n","    # Print out metrics\n","    # classification_report builds a text report showing the main classification metrics\n","    print('\\nTest results on each slice:')\n","    scores = classification_report(Y_true, Y_predict, target_names=class_names_original)\n","    scores_dict = classification_report(Y_true, Y_predict, target_names=class_names_original, output_dict=True)\n","    print(scores)\n","\n","    # Predict artist using pooling methodology\n","    pooling_scores, pooled_scores_dict = predict_artist(model, X_test, Y_test, S_test, le,\n","                                                        class_names=class_names_original, slices=None, verbose=False)\n","    del test_loader, X_test, Y_test, Y_true, Y_predict, S_test, le, class_names_original, \\\n","        inputs, labels, data\n","    gc.collect()\n","\n","    # Save metrics\n","    if save_metrics:\n","        plt.savefig(filename + '_pooled_confusion_matrix.png', bbox_inches=\"tight\")\n","        plt.close()\n","        with open(filename + '.txt', 'w') as f:\n","            f.write(\"Training data shape:\" + str(X_train_shape))\n","            f.write('\\nnb_classes: ' + str(nb_classes) + '\\nslice_length: ' + str(slice_length))\n","            f.write('\\nweights: ' + weights)\n","            f.write('\\nlr: ' + str(lr))\n","            #f.write('\\nTest score/loss: ' + str(score[0]))\n","            #f.write('\\nTest accuracy: ' + str(score[1]))\n","            f.write('\\nTest results on each slice:\\n')\n","            f.write(str(scores))\n","            f.write('\\n\\n Scores when pooling song slices:\\n')\n","            f.write(str(pooling_scores))\n","\n","    return (scores_dict, pooled_scores_dict)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oh1i3EY0wWkb"},"source":["**##############################################**\n","\n","**#################### MAIN #####################**\n","\n","**##############################################**"]},{"cell_type":"code","metadata":{"id":"WQfy1TNJml0k"},"source":["import librosa\n","import librosa.display\n","import random\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fs9HDiUIwvZQ"},"source":["def create_dataset(artist_folder='artists', save_folder='song_data', sr=16000, n_mels=128, \\\n","                   n_fft=2048, hop_length=512):\n","    \"\"\"\n","    This function creates the dataset given a folder with the correct structure (artist_folder/artists/albums/*.mp3)\n","    and saves it to a specified folder.\n","    :param artist_folder: folder with the correct structure (artist_folder/artists/albums/*.mp3)\n","    :param save_folder: folder to use for saving the created dataset\n","    :param sr: sampling rate\n","    :param n_mels: number of Mel bins\n","    :param n_fft: length of the FFT window\n","    :param hop_length: number of samples between successive frames\n","    \"\"\"\n","    # In windows an error is raised is the concatenated PATH is too long\n","    # For that reason, some names have been changed to avoid such problems\n","\n","    # get list of all artists\n","    os.makedirs(save_folder, exist_ok=True)\n","    artists = [path for path in os.listdir(artist_folder)] #if\n","               #os.path.isdir(path)]\n","    artists.sort()\n","\n","    # iterate through all artists, albums, songs and find mel spectrogram\n","    print('Creating songs dataset processing the following artists:')\n","    for artist in artists:\n","        print('> ' + artist)\n","        artist_path = os.path.join(artist_folder, artist)\n","        artist_albums = os.listdir(artist_path)\n","\n","        for album in artist_albums:\n","            album_path = os.path.join(artist_path, album)\n","            album_songs = os.listdir(album_path)\n","            album_songs.sort()\n","\n","            for song in album_songs:\n","                song_path = os.path.join(album_path, song)\n","\n","                # Create mel spectrogram and convert it to the log scale\n","                y, sr = librosa.load(song_path, sr=sr)\n","                S = librosa.feature.melspectrogram(y, sr=sr, n_mels=n_mels, \\\n","                                                   n_fft=n_fft, \\\n","                                                   hop_length=hop_length)\n","                log_S = librosa.amplitude_to_db(S, ref=1.0)\n","                data = (artist, log_S, song)\n","\n","                # Save each song\n","                save_name = artist + '_%%-%%_' + album + '_%%-%%_' + song\n","                with open(os.path.join(save_folder, save_name), 'wb') as fp:\n","                    dill.dump(data, fp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4yeUqOeFw1jr"},"source":["def create_spectrogram_plots(artist_folder='artists', sr=16000, n_mels=128, n_fft=2048, hop_length=512):\n","    \"\"\"\n","    Create a spectrogram from a randomly selected song for each artist and plot.\n","    :param artist_folder: folder with the correct structure (artist_folder/artists/albums/*.mp3)\n","    :param sr: sampling rate\n","    :param n_mels: number of Mel bins\n","    :param n_fft: length of the FFT window\n","    :param hop_length: number of samples between successive frames\n","    \"\"\"\n","\n","    # get list of all artists\n","    artists = os.listdir(artist_folder)\n","    artists.sort()\n","\n","    fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(14, 6), sharex=True, sharey=True)\n","\n","    row = 0\n","    col = 0\n","\n","    # iterate through artists, randomly select an album,\n","    # randomly select a song, and plot a spectrogram on a grid\n","    for artist in artists:\n","        # Randomly select album and song\n","        artist_path = os.path.join(artist_folder, artist)\n","        artist_albums = os.listdir(artist_path)\n","        album = random.choice(artist_albums)\n","        album_path = os.path.join(artist_path, album)\n","        album_songs = os.listdir(album_path)\n","        song = random.choice(album_songs)\n","        song_path = os.path.join(album_path, song)\n","\n","        # Create mel spectrogram\n","        y, sr = librosa.load(song_path, sr=sr, duration=3)\n","        S = librosa.feature.melspectrogram(y, sr=sr, n_mels=n_mels, \\\n","                                           n_fft=n_fft, hop_length=hop_length)\n","        log_S = librosa.amplitude_to_db(S, ref=1.0)\n","\n","        # Plot on grid\n","        plt.axes(ax[row, col])\n","        librosa.display.specshow(log_S, sr=sr)\n","        plt.title(artist)\n","        col += 1\n","        if col == 5:\n","            row += 1\n","            col = 0\n","\n","    fig.tight_layout()\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jgTP9D85xKM-"},"source":["**#############################################**\n","\n","**#################### RUN #####################**\n","\n","**#############################################**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-cKgv93Yw9FC","executionInfo":{"status":"ok","timestamp":1625566071303,"user_tz":-120,"elapsed":22199,"user":{"displayName":"Luca Francesco Rossi","photoUrl":"","userId":"16924310128743423726"}},"outputId":"2c41459f-b56d-46c6-ed27-928af93d544e"},"source":["# Mounting Google Drive in order to read the dataset\n","from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n","/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"keCxQ6EZziDf","executionInfo":{"status":"ok","timestamp":1625503331191,"user_tz":-120,"elapsed":23,"user":{"displayName":"Luca Francesco Rossi","photoUrl":"","userId":"16924310128743423726"}},"outputId":"2534e004-3958-4283-c2a5-398c1e2bb5a2"},"source":["!ls MyDrive/Colab\\ Datasets/GTZANplus/genres_original"],"execution_count":null,"outputs":[{"output_type":"stream","text":["blues  classical  country  disco  hiphop  jazz\tmetal  pop  reggae  rock\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kuP5sS0ezuhv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625503405860,"user_tz":-120,"elapsed":74682,"user":{"displayName":"Luca Francesco Rossi","photoUrl":"","userId":"16924310128743423726"}},"outputId":"51c6c089-50d1-47b5-cbf9-606280bd80ae"},"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","# Create dataset (therefore apply only once)\n","create_dataset(artist_folder='MyDrive/Colab Datasets/GTZANplus/genres_original', \\\n","               save_folder='MyDrive/Colab Datasets/GTZANplus/song_data', sr=22050, \\\n","               n_mels=128, n_fft=2048, hop_length=512)\n","\n","warnings.resetwarnings()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Creating songs dataset processing the following artists:\n","> blues\n","> classical\n","> country\n","> disco\n","> hiphop\n","> jazz\n","> metal\n","> pop\n","> reggae\n","> rock\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fRmGOohx2e91"},"source":["warnings.filterwarnings('ignore')\n","\n","# Create a spectrogram from a randomly selected song for each artist and plot\n","create_spectrogram_plots(artist_folder='MyDrive/Colab Datasets/GTZANplus/genres_original', sr=22050, n_mels=128, n_fft=2048, hop_length=512)\n","\n","warnings.resetwarnings()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yhNxJyHfAyIm"},"source":["# Lengths of slices\n","#slice_lengths = [911, 628, 313, 157, 94, 32]\n","slice_lengths = [130]  # 3s slice for sr = 22050\n","# Number of target artists\n","nb_classes = 10\n","# Learning rate\n","lr = 0.0001\n","# Patience (consecutive epochs without val loss improvement for EarlyStopping)\n","patience = 10\n","# List of random states for iteration\n","#random_state_list = [0, 21, 42]\n","random_state_list = [42]\n","# Number of outer iteration\n","#iterations = 3\n","iterations = 1\n","# Batch size\n","batch_size = 16\n","# Training epochs\n","nb_epochs = 200\n","# Folder for data augmentation\n","augment_folder = 'MyDrive/Colab Datasets/GTZANplus/augmented'\n","# Folder for the summary of metrics evaluation\n","summary_metrics_output_folder = 'MyDrive/Colab Datasets/GTZANplus/metrics/summary_metrics'\n","# Folder for the complete metrics evaluation for ALBUM SPLIT\n","save_metrics_album_split = 'MyDrive/Colab Datasets/GTZANplus/metrics/album_split_metrics'\n","# Folder for the complete metrics evaluation for SONG SPLIT\n","save_metrics_song_split = 'MyDrive/Colab Datasets/GTZANplus/metrics/song_split_metrics'\n","# Folder for the \"weights checkpoint\" for ALBUM SPLIT\n","save_weights_album_split = 'MyDrive/Colab Datasets/GTZANplus/weights/album_split_weights'\n","# Folder for the \"weights checkpoint\" for SONG SPLIT\n","save_weights_song_split = 'MyDrive/Colab Datasets/GTZANplus/weights/song_split_weights'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETP22HHrCyx3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625509207351,"user_tz":-120,"elapsed":5801511,"user":{"displayName":"Luca Francesco Rossi","photoUrl":"","userId":"16924310128743423726"}},"outputId":"464f1109-1d2f-4d72-882e-a626adc1f30f"},"source":["warnings.filterwarnings('ignore')\n","\n","# Run\n","for slice_len in slice_lengths:\n","\n","    scores_album_split = []\n","    pooling_scores_album_split = []\n","    scores_song_split = []\n","    pooling_scores_song_split = []\n","\n","    for i in range(iterations):\n","\n","        # Album split\n","        print('---------------------------------------------------------------------------')\n","        print(f'Training on album split level at outer iteration {i+1} for length {slice_len}...')\n","        print('---------------------------------------------------------------------------')\n","        score, pooling_score = train_model( \\\n","            nb_classes=nb_classes, \\\n","            slice_length=slice_len, \\\n","            artist_folder='MyDrive/Colab Datasets/artist20/mp3s-32k', \\\n","            song_folder='MyDrive/Colab Datasets/artist20/song_data', \\\n","            augment_folder = augment_folder, \\\n","            plots=True, \\\n","            train=True, \\\n","            load_checkpoint=True, \\\n","            save_metrics=True, \\\n","            save_metrics_folder=save_metrics_album_split, \\\n","            save_weights_folder=save_weights_album_split, \\\n","            batch_size=batch_size, \\\n","            nb_epochs=nb_epochs, \\\n","            lr=lr, \\\n","            patience=patience, \\\n","            album_split=True, \\\n","            random_states=random_state_list[i])\n","        scores_album_split.append(score['weighted avg'])\n","        pooling_scores_album_split.append(pooling_score['weighted avg'])\n","        # Release unreferenced memory\n","        gc.collect()\n","\n","        # Song split\n","        print('---------------------------------------------------------------------------')\n","        print(f'Training on song split level at outer iteration {i + 1} for slice {slice_len}...')\n","        print('---------------------------------------------------------------------------')\n","        score, pooling_score = train_model( \\\n","            nb_classes=nb_classes, \\\n","            slice_length=slice_len, \\\n","            artist_folder='MyDrive/Colab Datasets/GTZANplus/genres_original', \\\n","            song_folder='MyDrive/Colab Datasets/GTZANplus/song_data', \\\n","            augment_folder = augment_folder, \\\n","            plots=True, \\\n","            train=True, \\\n","            load_checkpoint=True, \\\n","            save_metrics=True, \\\n","            save_metrics_folder=save_metrics_song_split, \\\n","            save_weights_folder=save_weights_song_split, \\\n","            batch_size=batch_size, \\\n","            nb_epochs=nb_epochs, \\\n","            lr=lr, \\\n","            patience=patience, \\\n","            album_split=False, \\\n","            random_states=random_state_list[i])\n","        scores_song_split.append(score['weighted avg'])\n","        pooling_scores_song_split.append(pooling_score['weighted avg'])\n","        # Release unreferenced memory\n","        gc.collect()\n","\n","    # Save to .csv files\n","    os.makedirs(summary_metrics_output_folder, exist_ok=True)\n","    pd.DataFrame(scores_album_split).to_csv('{}/{}_album_split_score.csv'.format(summary_metrics_output_folder, slice_len))\n","    pd.DataFrame(pooling_scores_album_split).to_csv('{}/{}_album_split_pooled_score.csv'.format(summary_metrics_output_folder, slice_len))\n","    pd.DataFrame(scores_song_split).to_csv('{}/{}_song_split_score.csv'.format(summary_metrics_output_folder, slice_len))\n","    pd.DataFrame(pooling_scores_song_split).to_csv('{}/{}_song_split_pooled_score.csv'.format(summary_metrics_output_folder, slice_len))\n","    \n","warnings.resetwarnings()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["---------------------------------------------------------------------------\n","Training on song split level at outer iteration 1 for slice 130...\n","---------------------------------------------------------------------------\n","Loading dataset...\n","Loaded and split dataset. Slicing songs...\n","Augmenting train set...\n","Training set label counts: (array(['blues', 'classical', 'country', 'disco', 'hiphop', 'jazz',\n","       'metal', 'pop', 'reggae', 'rock'], dtype='<U9'), array([3645, 3663, 3663, 3666, 3729, 3687, 3645, 3645, 3645, 3657]))\n","Looking for previous weights...\n","No checkpoint file detected.  Starting from scratch.\n","Epoch 1 \t\t Training Loss: 1.512122 \t\t Validation Loss: 1.167706\n","Validation Loss Decreased(inf--->1.167706) \t Saving The Model\n","Epoch 2 \t\t Training Loss: 0.821066 \t\t Validation Loss: 0.915456\n","Validation Loss Decreased(1.167706--->0.915456) \t Saving The Model\n","Epoch 3 \t\t Training Loss: 0.547786 \t\t Validation Loss: 0.871726\n","Validation Loss Decreased(0.915456--->0.871726) \t Saving The Model\n","Epoch 4 \t\t Training Loss: 0.409037 \t\t Validation Loss: 0.877637\n","Epoch 5 \t\t Training Loss: 0.319013 \t\t Validation Loss: 0.802791\n","Validation Loss Decreased(0.871726--->0.802791) \t Saving The Model\n","Epoch 6 \t\t Training Loss: 0.262571 \t\t Validation Loss: 0.881663\n","Epoch 7 \t\t Training Loss: 0.227560 \t\t Validation Loss: 0.911883\n","Epoch 8 \t\t Training Loss: 0.194420 \t\t Validation Loss: 0.936241\n","Epoch 9 \t\t Training Loss: 0.168172 \t\t Validation Loss: 0.898347\n","Epoch 10 \t\t Training Loss: 0.148437 \t\t Validation Loss: 0.949627\n","Epoch 11 \t\t Training Loss: 0.130926 \t\t Validation Loss: 1.043294\n","Epoch 12 \t\t Training Loss: 0.119194 \t\t Validation Loss: 0.839265\n","Epoch 13 \t\t Training Loss: 0.109812 \t\t Validation Loss: 1.083329\n","Epoch 14 \t\t Training Loss: 0.103708 \t\t Validation Loss: 0.938990\n","Epoch 15 \t\t Training Loss: 0.091234 \t\t Validation Loss: 0.963378\n","Reached limit of 10 epochs without validation loss improvement: EarlyStopping.\n","Testing model...\n","\n","Test results on each slice:\n","              precision    recall  f1-score   support\n","\n","       blues       1.00      0.62      0.77        80\n","   classical       0.87      0.99      0.92        80\n","     country       0.71      0.62      0.67        80\n","       disco       0.84      0.70      0.76        80\n","      hiphop       0.68      0.94      0.79        81\n","        jazz       0.97      0.88      0.92        80\n","       metal       0.81      0.89      0.85        80\n","         pop       0.80      0.74      0.77        80\n","      reggae       0.92      0.81      0.86        80\n","        rock       0.48      0.63      0.54        81\n","\n","    accuracy                           0.78       802\n","   macro avg       0.81      0.78      0.78       802\n","weighted avg       0.81      0.78      0.78       802\n","\n","Test results when pooling slices by song and voting:\n","              precision    recall  f1-score   support\n","\n","       blues       1.00      0.70      0.82        10\n","   classical       0.83      1.00      0.91        10\n","     country       0.78      0.70      0.74        10\n","       disco       0.88      0.70      0.78        10\n","      hiphop       0.71      1.00      0.83        10\n","        jazz       1.00      0.90      0.95        10\n","       metal       0.83      1.00      0.91        10\n","         pop       0.89      0.80      0.84        10\n","      reggae       1.00      0.90      0.95        10\n","        rock       0.55      0.60      0.57        10\n","\n","    accuracy                           0.83       100\n","   macro avg       0.85      0.83      0.83       100\n","weighted avg       0.85      0.83      0.83       100\n","\n"],"name":"stdout"}]}]}